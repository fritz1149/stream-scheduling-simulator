{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext blackcellmagic\n",
    "import sys\n",
    "import uuid\n",
    "sys.path.insert(0, \"..\")\n",
    "def gen_uuid():\n",
    "    return str(uuid.uuid4())[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graph\n",
    "import importlib\n",
    "\n",
    "importlib.reload(graph)\n",
    "v1 = graph.Vertex(\"v1\", {\"connector\": \"robot\"}, 10000, 1, 10, int(1e8))\n",
    "v21 = graph.Vertex(\"v21\", {}, 10000, 1, 10, int(1e8))\n",
    "v22 = graph.Vertex(\"v22\", {}, 10000, 1, 10, int(1e8))\n",
    "v3 = graph.Vertex(\"v3\", {\"machine\": \"rack\"}, 0, 0, 10, int(1e8))\n",
    "g = graph.ExecutionGraph(gen_uuid())\n",
    "g.add_vertex(v1)\n",
    "g.add_vertex(v21)\n",
    "g.add_vertex(v22)\n",
    "g.add_vertex(v3)\n",
    "g.connect(v1, v21, 10000, 10)\n",
    "g.connect(v1, v22, 10000, 1)\n",
    "g.connect(v21, v3, 2000, 1)\n",
    "g.connect(v22, v3, 1000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(g.get_vertices())\n",
    "# print(g.get_edges())\n",
    "# print(g.get_sources())\n",
    "# print(g.get_sinks())\n",
    "import networkx as nx\n",
    "nx.draw(g.g, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import min_cut\n",
    "importlib.reload(min_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_cut, t_cut = min_cut.min_cut(g)\n",
    "print(s_cut, t_cut)\n",
    "s_graph = g.sub_graph(s_cut, gen_uuid())\n",
    "t_graph = g.sub_graph(t_cut, gen_uuid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import yaml\n",
    "import topo\n",
    "importlib.reload(topo)\n",
    "data = yaml.load(open('../samples/a0.yaml', 'r').read(), Loader=yaml.Loader)\n",
    "sc = topo.Scenario.from_dict(data)\n",
    "nx.draw(sc.topo.g, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import schedule as sch\n",
    "importlib.reload(sch)\n",
    "edge_random_scheduler = sch.RandomScheduler(sc.get_edge_domains()[0].topo)\n",
    "cloud_random_scheduler = sch.RandomScheduler(sc.get_cloud_domains()[0].topo)\n",
    "sr1 = edge_random_scheduler.schedule(s_graph)\n",
    "sr2 = cloud_random_scheduler.schedule(t_graph)\n",
    "global_random_scheduler = sch.RandomScheduler(sc.topo)\n",
    "comp_sr = global_random_scheduler.schedule(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculator = sch.LatencyCalculator(sc.topo)\n",
    "result = sch.SchedulingResult.merge(sr1, sr2)\n",
    "calculator.add_scheduled_graph(g, result)\n",
    "print(calculator.compute_latency())\n",
    "sc.topo.clear_occupied()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_cal = sch.LatencyCalculator(sc.topo)\n",
    "comp_cal.add_scheduled_graph(g, comp_sr)\n",
    "print(comp_cal.compute_latency())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "add1a61ff37513b0d798fa9b3ddbf8ae573dfe73fde377561c8d981e86c7d8d4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
